{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
      "\n",
      "  int_rate  installment grade sub_grade    ...    last_pymnt_amnt  \\\n",
      "0   10.65%       162.87     B        B2    ...             171.62   \n",
      "\n",
      "  last_credit_pull_d collections_12_mths_ex_med  policy_code application_type  \\\n",
      "0           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
      "\n",
      "  acc_now_delinq chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies  \\\n",
      "0            0.0                      0.0         0.0                  0.0   \n",
      "\n",
      "  tax_liens  \n",
      "0       0.0  \n",
      "\n",
      "[1 rows x 52 columns]\n",
      "52\n",
      "   loan_amnt        term int_rate  installment emp_length home_ownership  \\\n",
      "0     5000.0   36 months   10.65%       162.87  10+ years           RENT   \n",
      "\n",
      "   annual_inc verification_status loan_status pymnt_plan    ...      \\\n",
      "0     24000.0            Verified  Fully Paid          n    ...       \n",
      "\n",
      "  initial_list_status last_credit_pull_d collections_12_mths_ex_med  \\\n",
      "0                   f           Jun-2016                        0.0   \n",
      "\n",
      "   policy_code  application_type acc_now_delinq  chargeoff_within_12_mths  \\\n",
      "0          1.0        INDIVIDUAL            0.0                       0.0   \n",
      "\n",
      "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
      "0          0.0                   0.0        0.0  \n",
      "\n",
      "[1 rows x 32 columns]\n",
      "32\n",
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "## 3. Reading in to Pandas ##\n",
    "\n",
    "import pandas as pd\n",
    "loans_2007 = pd.read_csv(\"loans_2007.csv\")\n",
    "print(loans_2007.head(1))\n",
    "print(len(loans_2007.columns))\n",
    "\n",
    "## 5. First group of columns ##\n",
    "\n",
    "loans_2007.drop([\"id\", \"member_id\", \"funded_amnt\", \"funded_amnt_inv\", \"grade\", \"sub_grade\", \"emp_title\", \"issue_d\"], axis =1, inplace = True)\n",
    "\n",
    "## 7. Second group of features ##\n",
    "\n",
    "loans_2007.drop([\"zip_code\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\"], axis =1, inplace = True)\n",
    "\n",
    "## 9. Third group of features ##\n",
    "\n",
    "loans_2007.drop([\"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\"], axis = 1, inplace=True)\n",
    "print(loans_2007.head(1))\n",
    "print(len(loans_2007.columns))\n",
    "\n",
    "## 10. Target column ##\n",
    "\n",
    "loans_2007[\"loan_status\"].value_counts()\n",
    "\n",
    "## 12. Binary classification ##\n",
    "\n",
    "loans_2007 = loans_2007[(loans_2007[\"loan_status\"] == \"Fully Paid\") | (loans_2007[\"loan_status\"] == \"Charged Off\")]\n",
    "\n",
    "mapping_dict = { \"loan_status\": { \"Fully Paid\" :  1, \"Charged Off\" : 0}}\n",
    "loans_2007.replace(mapping_dict, inplace = True)\n",
    "\n",
    "## 13. Removing single value columns ##\n",
    "\n",
    "drop_columns = []\n",
    "for column in loans_2007.columns:\n",
    "    non_null = loans_2007[column].dropna()\n",
    "    unique_non_null = non_null.unique()\n",
    "    if len(unique_non_null) == 1:\n",
    "        drop_columns.append(column)\n",
    "\n",
    "loans_2007.drop(drop_columns, axis=1, inplace = True)\n",
    "print(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     11\n",
      "float64    10\n",
      "int64       1\n",
      "dtype: int64\n",
      "Col: home_ownership\n",
      "RENT        18513\n",
      "MORTGAGE    17112\n",
      "OWN          2984\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "Col: verification_status\n",
      "Not Verified       16696\n",
      "Verified           12290\n",
      "Source Verified     9722\n",
      "Name: verification_status, dtype: int64\n",
      "Col: emp_length\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1229\n",
      "n/a          1032\n",
      "Name: emp_length, dtype: int64\n",
      "Col: term\n",
      " 36 months    29041\n",
      " 60 months     9667\n",
      "Name: term, dtype: int64\n",
      "Col: addr_state\n",
      "CA    6958\n",
      "NY    3713\n",
      "FL    2791\n",
      "TX    2667\n",
      "NJ    1798\n",
      "IL    1483\n",
      "PA    1473\n",
      "VA    1376\n",
      "GA    1364\n",
      "MA    1301\n",
      "OH    1179\n",
      "MD    1026\n",
      "AZ     850\n",
      "WA     822\n",
      "CO     770\n",
      "NC     753\n",
      "CT     730\n",
      "MI     712\n",
      "MO     671\n",
      "MN     603\n",
      "NV     481\n",
      "SC     462\n",
      "WI     441\n",
      "AL     437\n",
      "OR     436\n",
      "LA     430\n",
      "KY     315\n",
      "OK     290\n",
      "KS     260\n",
      "UT     254\n",
      "AR     237\n",
      "DC     209\n",
      "RI     196\n",
      "NM     184\n",
      "WV     172\n",
      "NH     166\n",
      "HI     166\n",
      "DE     113\n",
      "MT      83\n",
      "WY      80\n",
      "AK      78\n",
      "SD      61\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "IA       5\n",
      "NE       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n",
      "debt_consolidation    18130\n",
      "credit_card            5039\n",
      "other                  3864\n",
      "home_improvement       2897\n",
      "major_purchase         2155\n",
      "small_business         1762\n",
      "car                    1510\n",
      "wedding                 929\n",
      "medical                 680\n",
      "moving                  576\n",
      "vacation                375\n",
      "house                   369\n",
      "educational             320\n",
      "renewable_energy        102\n",
      "Name: purpose, dtype: int64\n",
      "Debt Consolidation                         2104\n",
      "Debt Consolidation Loan                    1632\n",
      "Personal Loan                               642\n",
      "Consolidation                               494\n",
      "debt consolidation                          485\n",
      "Credit Card Consolidation                   353\n",
      "Home Improvement                            346\n",
      "Debt consolidation                          324\n",
      "Small Business Loan                         310\n",
      "Credit Card Loan                            305\n",
      "Personal                                    302\n",
      "Consolidation Loan                          251\n",
      "Home Improvement Loan                       234\n",
      "personal loan                               227\n",
      "personal                                    211\n",
      "Loan                                        208\n",
      "Wedding Loan                                201\n",
      "Car Loan                                    195\n",
      "consolidation                               193\n",
      "Other Loan                                  181\n",
      "Credit Card Payoff                          150\n",
      "Wedding                                     149\n",
      "Credit Card Refinance                       143\n",
      "Major Purchase Loan                         139\n",
      "Consolidate                                 125\n",
      "Medical                                     118\n",
      "Credit Card                                 115\n",
      "home improvement                            107\n",
      "My Loan                                      92\n",
      "Credit Cards                                 91\n",
      "                                           ... \n",
      "Short Term Consolidation-- Thank you!         1\n",
      "High APR Consolidation Loan                   1\n",
      "personel loan                                 1\n",
      "may                                           1\n",
      "Life-Saver Loan                               1\n",
      "Michael's loan                                1\n",
      "Would like to lower interest rate             1\n",
      "Combine 2                                     1\n",
      "bill loan                                     1\n",
      "brighter future                               1\n",
      "Swimming Pool Renovation                      1\n",
      "Relo - Closing Negative Equity Mortgage       1\n",
      "Elementary School Teacher Needs Help          1\n",
      "Buissness CP                                  1\n",
      "Lower Interest, Lower Payments                1\n",
      "Help from Abroad                              1\n",
      "Pay Off High Interest Credit Cards.           1\n",
      "Reduce CC Rate Loan                           1\n",
      "Time to Shine 2010                            1\n",
      "Savethedyloan                                 1\n",
      "Get rid of high interest credit cards         1\n",
      "Credit Card Loa                               1\n",
      "Consolidation Step Loan                       1\n",
      "Need a better rate                            1\n",
      "Needed Money                                  1\n",
      "Feb4K                                         1\n",
      "TEA's loan                                    1\n",
      "School and debt consolidation                 1\n",
      "J.L.                                          1\n",
      "PAY MY CAR PAYMENT IN FULL..                  1\n",
      "Name: title, Length: 19332, dtype: int64\n",
      "   loan_amnt        term  int_rate  installment  emp_length home_ownership  \\\n",
      "0     5000.0   36 months     10.65       162.87          10           RENT   \n",
      "\n",
      "   annual_inc verification_status  loan_status      purpose    dti  \\\n",
      "0     24000.0            Verified            1  credit_card  27.65   \n",
      "\n",
      "   delinq_2yrs  inq_last_6mths  open_acc  pub_rec  revol_bal  revol_util  \\\n",
      "0          0.0             1.0       3.0      0.0    13648.0        83.7   \n",
      "\n",
      "   total_acc  \n",
      "0        9.0  \n"
     ]
    }
   ],
   "source": [
    "## 1. Recap ##\n",
    "\n",
    "import pandas as pd\n",
    "loans = loans_2007\n",
    "null_counts = loans.isnull().sum()\n",
    "\n",
    "## 2. Handling missing values ##\n",
    "\n",
    "loans.drop([\"pub_rec_bankruptcies\"], axis =1, inplace = True)\n",
    "loans.dropna(inplace = True)\n",
    "'''\n",
    "for col in loans.columns:\n",
    "    print(loans[col].dtypes)\n",
    "    print(loans[col].value_counts)\n",
    "'''\n",
    "print(loans.dtypes.value_counts())\n",
    "\n",
    "## 3. Text columns ##\n",
    "\n",
    "object_columns_df = loans.select_dtypes(include = [\"object\"])\n",
    "object_columns_df.head(1)\n",
    "\n",
    "## 5. First 5 categorical columns ##\n",
    "\n",
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for col in cols:\n",
    "    print(\"Col: \" + col)\n",
    "    print(object_columns_df[col].value_counts())\n",
    "\n",
    "## 6. The reason for the loan ##\n",
    "\n",
    "print(object_columns_df[\"purpose\"].value_counts())\n",
    "print(object_columns_df[\"title\"].value_counts())\n",
    "\n",
    "## 7. Categorical columns ##\n",
    "\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans.drop([\"last_credit_pull_d\", \"addr_state\", \"title\", \"earliest_cr_line\"], axis =1, inplace = True)\n",
    "loans['int_rate'] = loans['int_rate'].str.rstrip('%').astype(float)\n",
    "loans['revol_util'] = loans['revol_util'].str.rstrip('%').astype(float)\n",
    "\n",
    "loans = loans.replace(mapping_dict)\n",
    "print(loans.head(1))\n",
    "\n",
    "## 8. Dummy variables ##\n",
    "\n",
    "cat_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "dummy_df = pd.get_dummies(loans[cat_columns])\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "loans = loans.drop(cat_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [37, 38708]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f2323757b0ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mfp_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loan_status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \"\"\"\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 173\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [37, 38708]"
     ]
    }
   ],
   "source": [
    "\n",
    "# tn = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "# tp = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "# fn = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "# fp = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "\n",
    "## 5. Class imbalance ##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# Predict that all loans will be paid off on time.\n",
    "predictions = pd.Series(numpy.ones(loans.shape[0]))\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "## 6. Logistic Regression ##\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lr = LogisticRegression()\n",
    "features = list(loans.columns)\n",
    "features.remove(\"loan_status\")\n",
    "target = loans[\"loan_status\"]\n",
    "lr.fit(loans[features], target)\n",
    "predictions = lr.predict(loans[features])\n",
    "\n",
    "## 7. Cross Validation ##\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_predict, KFold\n",
    "lr = LogisticRegression()\n",
    "kf = KFold(np.shape(features)[0], random_state=1)\n",
    "predictions = cross_val_predict(lr, features, target, cv = kf)\n",
    "predictions = pd.Series(predictions)\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "## 9. Penalizing the classifier ##\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "lr = LogisticRegression(class_weight = \"balanced\")\n",
    "kf = KFold(features.shape[0], random_state = 1)\n",
    "predictions = cross_val_predict(lr, features, target, cv = kf)\n",
    "predictions = pd.Series(predictions)\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "## 10. Manual penalties ##\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "penalty = {0:10, 1:1}\n",
    "lr = LogisticRegression(class_weight = penalty)\n",
    "kf = KFold(features.shape[0], random_state = 1)\n",
    "predictions = cross_val_predict(lr, features, target, cv = kf)\n",
    "predictions = pd.Series(predictions)\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "## 11. Random forests ##\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "lr = RandomForestClassifier(class_weight = \"balanced\", random_state = 1)\n",
    "kf = KFold(features.shape[0], random_state = 1)\n",
    "predictions = cross_val_predict(lr, features, target, cv = kf)\n",
    "predictions = pd.Series(predictions)\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "'''\n",
    "We can tweak the penalties further.\n",
    "We can try models other than a random forest and logistic regression.\n",
    "We can use some of the columns we discarded to generate better features.\n",
    "We can ensemble multiple models to get more accurate predictions.\n",
    "We can tune the parameters of the algorithm to achieve higher performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
